{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "686dde42-8e47-46b9-8fe5-beff78e60777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries for data manipulation and numerical operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing  # For parallel processing to speed up tasks\n",
    "import gensim  # For word embeddings and other NLP tasks\n",
    "import nltk  # For natural language processing tasks like tokenization and stemming\n",
    "import spacy  # For advanced NLP tasks like named entity recognition and dependency parsing\n",
    "\n",
    "# Importing a custom utility for creating mean word embeddings\n",
    "from UtilWordEmbedding import MeanEmbeddingVectorizer\n",
    "\n",
    "# Importing tools from scikit-learn for building machine learning pipelines\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.compose import ColumnTransformer  # For transforming columns of data\n",
    "from sklearn.base import BaseEstimator, TransformerMixin  # Base classes for custom transformers\n",
    "\n",
    "# Importing text preprocessing functions from gensim\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric, strip_short\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces, strip_non_alphanum, remove_stopwords, stem_text\n",
    "\n",
    "# Importing the Word2Vec model from gensim for creating word embeddings\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "# Importing lemmatizers and stemmers from nltk for word normalization\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "# Importing tools from scikit-learn for encoding categorical variables and converting text data into numerical features\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Importing various machine learning algorithms from scikit-learn and xgboost for classification tasks\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Importing tools for evaluating and selecting machine learning models\n",
    "from sklearn import metrics  # For performance evaluation\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.model_selection import cross_val_score  # For cross-validation\n",
    "from sklearn.model_selection import KFold, GridSearchCV  # For K-Fold cross-validation and hyperparameter tuning\n",
    "\n",
    "# Importing tqdm for displaying progress bars during iterative processes\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importing stopwords from nltk and setting them up\n",
    "from nltk.corpus import stopwords \n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "# Setting options for pandas to adjust how data frames are displayed\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Enabling inline plotting in Jupyter notebooks and setting a better quality for inline plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Setting a random seed to ensure reproducibility of results\n",
    "SEED=26\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bd08398a-7984-40ea-8660-1885f5faa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0db52f5e-1264-4cd4-a5e7-1393e3f2a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths to the hygiene dataset files\n",
    "hygiene_data_path = \"C:\\\\Users\\\\kasam\\\\OneDrive\\\\Desktop\\\\data\\\\Hygiene\\\\hygiene.dat\"  # Path to the hygiene data file\n",
    "hygiene_labels_path = \"C:\\\\Users\\\\kasam\\\\OneDrive\\\\Desktop\\\\data\\\\Hygiene\\\\hygiene.dat.labels\"  # Path to the hygiene labels file\n",
    "hygiene_extra_path = \"C:\\\\Users\\\\kasam\\\\OneDrive\\\\Desktop\\\\data\\\\Hygiene\\\\hygiene.dat.additional\"  # Path to the hygiene additional data file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989811f3-95f6-4760-934d-948df0a76775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae13110b-8eb5-4562-b457-32f9a6dcd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Prep (Stop words removal, cleaning and Tokenization, steaming and Lemanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "eb6dc4c8-4899-4c53-badf-a298bdd83bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of preprocessing filters to apply to text\n",
    "TEXT_FILTERS = [\n",
    "    lambda text: text.lower(),  # Convert text to lowercase\n",
    "    strip_tags,  # Remove HTML tags\n",
    "    strip_punctuation,  # Replace punctuation characters with spaces\n",
    "    strip_multiple_whitespaces,  # Remove repeating whitespaces\n",
    "    gensim.parsing.preprocessing.remove_stopwords,  # Remove stopwords\n",
    "    strip_short,  # Remove words less than minsize=3 characters long\n",
    "    stem_text  # Stem the text\n",
    "]\n",
    "\n",
    "def preprocess_text(input_text):\n",
    "    \"\"\"\n",
    "    Preprocess the input text by applying a series of filters and lemmatizing the tokens.\n",
    "    \n",
    "    Filters applied:\n",
    "    - Convert text to lowercase\n",
    "    - Remove HTML tags\n",
    "    - Replace punctuation characters with spaces\n",
    "    - Remove repeating whitespaces\n",
    "    - Remove stopwords\n",
    "    - Remove words less than 3 characters long\n",
    "    - Stem the text\n",
    "    \n",
    "    Parameters:\n",
    "    input_text (str): The input text to preprocess.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of lemmatized tokens.\n",
    "    \"\"\"\n",
    "    lemmatized_tokens = []\n",
    "    for token in gensim.parsing.preprocessing.preprocess_string(input_text, TEXT_FILTERS):\n",
    "        lemmatized_tokens.append(WordNetLemmatizer().lemmatize(token))\n",
    "    return lemmatized_tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df81598-64c4-4b00-9d86-ed082c5ed774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cbac06d3-66a8-4ec8-94d9-d9c7e479cc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13299/13299 [02:33<00:00, 86.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 158.80067038536072 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Start timing the execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Variables for storing raw and processed texts\n",
    "raw_texts = []\n",
    "processed_texts = []\n",
    "\n",
    "# Read lines from the hygiene data file\n",
    "with open(hygiene_data_path) as file:\n",
    "    raw_texts = file.readlines()\n",
    "\n",
    "# Preprocess each text in raw_texts and append the results to processed_texts\n",
    "for text in tqdm(raw_texts):\n",
    "    stemmed_result = preprocess_text(text)\n",
    "    processed_texts.append(stemmed_result)\n",
    "\n",
    "# Combine processed tokens into single strings for each text\n",
    "final_processed_texts = [\" \".join(text) for text in processed_texts]\n",
    "\n",
    "# End timing the execution\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the execution time\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7dc50-abe2-4dda-ab61-3d7cf00ef7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "574ecbff-459a-470b-886b-72280045b72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13299 entries, 0 to 13298\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   label               13299 non-null  object\n",
      " 1   text                13299 non-null  object\n",
      " 2   preprocessed_texts  13299 non-null  object\n",
      " 3   tokenized_texts     13299 non-null  object\n",
      " 4   cuisines_offered    13299 non-null  object\n",
      " 5   zipcode             13299 non-null  object\n",
      " 6   num_reviews         13299 non-null  object\n",
      " 7   avg_rating          13299 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 831.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_texts</th>\n",
       "      <th>tokenized_texts</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The baguettes and rolls are excellent, and alt...</td>\n",
       "      <td>baguett roll excel haven tri excit dozen plu t...</td>\n",
       "      <td>[baguett, roll, excel, haven, tri, excit, doze...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I live up the street from Betty. &amp;#160;When my...</td>\n",
       "      <td>live street betti 160 sister town spring break...</td>\n",
       "      <td>[live, street, betti, 160, sister, town, sprin...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm worried about how I will review this place...</td>\n",
       "      <td>worri review place strongli think bad night pl...</td>\n",
       "      <td>[worri, review, place, strongli, think, bad, n...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Why can't you access them on Google street vie...</td>\n",
       "      <td>access googl street view like medina yarrow po...</td>\n",
       "      <td>[access, googl, street, view, like, medina, ya...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Things to like about this place: homemade guac...</td>\n",
       "      <td>thing like place homemad guacamol varieti tast...</td>\n",
       "      <td>[thing, like, place, homemad, guacamol, variet...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text                                 preprocessed_texts                                    tokenized_texts                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0     1  The baguettes and rolls are excellent, and alt...  baguett roll excel haven tri excit dozen plu t...  [baguett, roll, excel, haven, tri, excit, doze...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1     1  I live up the street from Betty. &#160;When my...  live street betti 160 sister town spring break...  [live, street, betti, 160, sister, town, sprin...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2     1  I'm worried about how I will review this place...  worri review place strongli think bad night pl...  [worri, review, place, strongli, think, bad, n...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3     0  Why can't you access them on Google street vie...  access googl street view like medina yarrow po...  [access, googl, street, view, like, medina, ya...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4     0  Things to like about this place: homemade guac...  thing like place homemad guacamol varieti tast...  [thing, like, place, homemad, guacamol, variet...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "N = 546\n",
    "\n",
    "# Read labels from the hygiene labels file\n",
    "with open(hygiene_labels_path, 'r') as file:\n",
    "    label_list = [line.rstrip() for line in file]\n",
    "\n",
    "# Creating a DataFrame from the processed texts and labels\n",
    "data_frame = pd.DataFrame({\n",
    "    \"label\": label_list,\n",
    "    \"text\": raw_texts, \n",
    "    \"preprocessed_texts\": final_processed_texts,\n",
    "    \"tokenized_texts\": processed_texts\n",
    "})\n",
    "\n",
    "# Reading additional hygiene data\n",
    "additional_data = pd.read_csv(\n",
    "    hygiene_extra_path,  \n",
    "    names=[\"cuisines_offered\", \"zipcode\", \"num_reviews\", \"avg_rating\"],\n",
    "    dtype={\n",
    "        \"cuisines_offered\": str, \n",
    "        \"zipcode\": str,\n",
    "        \"num_reviews\": str\n",
    "    }\n",
    ")\n",
    "\n",
    "# Joining the additional data with the main DataFrame\n",
    "data_frame = data_frame.join(additional_data)\n",
    "\n",
    "# Rounding and converting the average rating to an integer string\n",
    "data_frame['avg_rating'] = data_frame['avg_rating'].apply(lambda x: str(int(round(float(x), 0))))\n",
    "\n",
    "# Displaying information about the DataFrame and the first few rows\n",
    "print(data_frame.info())\n",
    "display(data_frame.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b2608549-1082-49ec-9afd-e8c4632fc7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9f432b93-9368-4462-a7b2-ead707e7e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 5) (546, 5) (546, 5) (546,)\n",
      "(12753, 5) (12753, 5) (12753, 5) (12753,)\n",
      "text                object\n",
      "cuisines_offered    object\n",
      "zipcode             object\n",
      "num_reviews         object\n",
      "avg_rating          object\n",
      "dtype: object preprocessed_texts    object\n",
      "cuisines_offered      object\n",
      "zipcode               object\n",
      "num_reviews           object\n",
      "avg_rating            object\n",
      "dtype: object tokenized_texts     object\n",
      "cuisines_offered    object\n",
      "zipcode             object\n",
      "num_reviews         object\n",
      "avg_rating          object\n",
      "dtype: object\n",
      "Execution time: 3.625620126724243 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_df = df[df[\"label\"] != \"[None]\"]\n",
    "test_df = df[df[\"label\"] == \"[None]\"]\n",
    "\n",
    "additional_feats = [\"cuisines_offered\", \"zipcode\", \"num_reviews\", \"avg_rating\"]\n",
    "\n",
    "train = train_df[[\"text\"] + additional_feats]\n",
    "train_preprocessed = train_df[[\"preprocessed_texts\"] + additional_feats]\n",
    "train_tokenized = train_df[[\"tokenized_texts\"] + additional_feats]\n",
    "train_labels = train_df[\"label\"].astype(int)  # needed by sklearn\n",
    "\n",
    "test = test_df[[\"text\"] + additional_feats]\n",
    "test_preprocessed = test_df[[\"preprocessed_texts\"] + additional_feats]\n",
    "test_tokenized = test_df[[\"tokenized_texts\"] + additional_feats]\n",
    "test_labels = test_df[\"label\"]\n",
    "\n",
    "print(train.shape, train_preprocessed.shape, train_tokenized.shape, train_labels.shape)\n",
    "print(test.shape, test_preprocessed.shape, test_tokenized.shape, test_labels.shape)\n",
    "print(train.dtypes, train_preprocessed.dtypes, train_tokenized.dtypes)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b1fd2-8f59-4a3f-a882-659919818e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "70e86e70-e14d-4f5c-a926-931c7ef22dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The baguettes and rolls are excellent, and alt...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live up the street from Betty. &amp;#160;When my...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm worried about how I will review this place...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why can't you access them on Google street vie...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Things to like about this place: homemade guac...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0  The baguettes and rolls are excellent, and alt...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1  I live up the street from Betty. &#160;When my...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2  I'm worried about how I will review this place...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3  Why can't you access them on Google street vie...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4  Things to like about this place: homemade guac...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_texts</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baguett roll excel haven tri excit dozen plu t...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>live street betti 160 sister town spring break...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worri review place strongli think bad night pl...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>access googl street view like medina yarrow po...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thing like place homemad guacamol varieti tast...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  preprocessed_texts                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0  baguett roll excel haven tri excit dozen plu t...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1  live street betti 160 sister town spring break...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2  worri review place strongli think bad night pl...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3  access googl street view like medina yarrow po...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4  thing like place homemad guacamol varieti tast...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_texts</th>\n",
       "      <th>cuisines_offered</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[baguett, roll, excel, haven, tri, excit, doze...</td>\n",
       "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
       "      <td>98118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[live, street, betti, 160, sister, town, sprin...</td>\n",
       "      <td>['American (New)', 'Restaurants']</td>\n",
       "      <td>98109</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[worri, review, place, strongli, think, bad, n...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98103</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[access, googl, street, view, like, medina, ya...</td>\n",
       "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
       "      <td>98112</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thing, like, place, homemad, guacamol, variet...</td>\n",
       "      <td>['Mexican', 'Restaurants']</td>\n",
       "      <td>98102</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     tokenized_texts                             cuisines_offered zipcode num_reviews avg_rating\n",
       "0  [baguett, roll, excel, haven, tri, excit, doze...  ['Vietnamese', 'Sandwiches', 'Restaurants']   98118           4          4\n",
       "1  [live, street, betti, 160, sister, town, sprin...            ['American (New)', 'Restaurants']   98109          21          4\n",
       "2  [worri, review, place, strongli, think, bad, n...                   ['Mexican', 'Restaurants']   98103          14          3\n",
       "3  [access, googl, street, view, like, medina, ya...        ['Mexican', 'Tex-Mex', 'Restaurants']   98112          42          4\n",
       "4  [thing, like, place, homemad, guacamol, variet...                   ['Mexican', 'Restaurants']   98102          12          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head())\n",
    "display(train_preprocessed.head())\n",
    "display(train_tokenized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5d7ac2d5-213b-455e-a392-47d866722487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62650104 0.72474747 0.67792317 0.68783693 0.60507246]\n",
      "Average F1-Score: 0.66442\n",
      "CPU times: total: 9.95 s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "#Model Experiment (Naive Bayers, SVM, Logistic Regression , Random Forest, XGBoost)\n",
    "\n",
    "%%time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(max_df=7, token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "         ('text', TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=3,\n",
    "                    max_df=0.5,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=500), 'preprocessed_texts')],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "# scores = metrics.f1_score(y_test, y_pred)\n",
    "scores = cross_val_score(pipeline, train_preprocessed, train_labels, cv=5, scoring= 'f1_macro')\n",
    "print(scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0627f57b-c7e7-4743-ba75-4425c361ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 scores: [0.62650104 0.72474747 0.67792317 0.68783693 0.60507246]\n",
      "Average F1-Score: 0.66442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming train_preprocessed and train_labels are defined and contain your data\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "            ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "            ('num_reviews', CountVectorizer(max_df=7, token_pattern=r'\\d+'), 'num_reviews'),\n",
    "            ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "            ('text', TfidfVectorizer(\n",
    "                        stop_words='english',\n",
    "                        strip_accents='unicode',\n",
    "                        min_df=3,\n",
    "                        max_df=0.5,\n",
    "                        ngram_range=(1, 3),\n",
    "                        max_features=500), 'preprocessed_texts')],\n",
    "        remainder='passthrough'\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# Assuming train_preprocessed and train_labels are defined and contain your data\n",
    "scores = cross_val_score(pipeline, train_preprocessed, train_labels, cv=5, scoring='f1_macro')\n",
    "print(\"Cross-validation F1 scores:\", scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bac753-9621-4c2e-9062-0ff1b4e3ee3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "01694db4-b0cd-462c-b075-971e2c6aed3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 scores: [0.62857143 0.72222222 0.68965517 0.66037736 0.54347826]\n",
      "Average F1-Score: 0.64886\n",
      "Execution time: 23.31 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Define your data: Assuming 'train' is your feature matrix and 'train_labels' are your target labels\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        transformers=[\n",
    "            # CountVectorizer for 'cuisines_offered' column\n",
    "            ('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "            \n",
    "            # OneHotEncoder for 'zipcode' column\n",
    "            ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "            \n",
    "            # CountVectorizer for 'num_reviews' column, using digits as tokens\n",
    "            ('num_reviews', CountVectorizer(max_df=7, token_pattern=r'\\d+'), 'num_reviews'),\n",
    "            \n",
    "            # OneHotEncoder for 'avg_rating' column\n",
    "            ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "            \n",
    "            # TfidfVectorizer for 'text' column\n",
    "            ('text', TfidfVectorizer(\n",
    "                        stop_words='english',\n",
    "                        strip_accents='unicode',\n",
    "                        min_df=3,\n",
    "                        max_df=0.5,\n",
    "                        ngram_range=(1, 3),\n",
    "                        max_features=500), 'text')],\n",
    "        remainder='passthrough'  # Pass through any remaining columns\n",
    "    )),\n",
    "    ('clf', MultinomialNB())  # Multinomial Naive Bayes classifier\n",
    "], verbose=False)\n",
    "\n",
    "# Cross-validation to evaluate the pipeline\n",
    "scores = cross_val_score(pipeline, train, train_labels, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1 scores:\", scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))\n",
    "\n",
    "# Calculate and print the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: %0.2f seconds\" % execution_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984f3889-0749-429f-bc42-6252ebbd661c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "be2a88e6-2377-4820-a9b5-2d642f782575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'num_reviews': 158\n",
      "\n",
      "Value counts for 'num_reviews':\n",
      "num_reviews\n",
      "1      2193\n",
      "2      1480\n",
      "3      1126\n",
      "4       934\n",
      "5       767\n",
      "6       675\n",
      "7       600\n",
      "8       484\n",
      "9       458\n",
      "10      403\n",
      "11      352\n",
      "12      315\n",
      "13      268\n",
      "14      246\n",
      "16      200\n",
      "15      199\n",
      "17      185\n",
      "18      160\n",
      "19      131\n",
      "20      125\n",
      "21      124\n",
      "22      124\n",
      "23      107\n",
      "24      101\n",
      "25       97\n",
      "28       86\n",
      "26       81\n",
      "27       77\n",
      "29       68\n",
      "30       60\n",
      "32       52\n",
      "33       51\n",
      "37       44\n",
      "36       44\n",
      "34       43\n",
      "31       43\n",
      "35       42\n",
      "39       39\n",
      "44       37\n",
      "38       33\n",
      "43       30\n",
      "47       28\n",
      "42       27\n",
      "40       26\n",
      "46       25\n",
      "45       25\n",
      "41       23\n",
      "54       22\n",
      "59       20\n",
      "55       15\n",
      "63       15\n",
      "49       15\n",
      "52       15\n",
      "51       14\n",
      "62       14\n",
      "48       14\n",
      "73       13\n",
      "57       12\n",
      "61       11\n",
      "50       11\n",
      "56       11\n",
      "58       10\n",
      "53       10\n",
      "66        9\n",
      "78        9\n",
      "67        8\n",
      "89        8\n",
      "83        8\n",
      "60        8\n",
      "65        7\n",
      "64        6\n",
      "93        6\n",
      "69        6\n",
      "70        6\n",
      "77        6\n",
      "76        5\n",
      "112       5\n",
      "85        5\n",
      "84        5\n",
      "91        4\n",
      "100       4\n",
      "68        4\n",
      "74        4\n",
      "80        4\n",
      "88        3\n",
      "86        3\n",
      "101       3\n",
      "72        3\n",
      "122       3\n",
      "142       3\n",
      "136       3\n",
      "75        3\n",
      "105       3\n",
      "107       3\n",
      "123       2\n",
      "90        2\n",
      "125       2\n",
      "95        2\n",
      "92        2\n",
      "116       2\n",
      "81        2\n",
      "110       2\n",
      "102       2\n",
      "130       2\n",
      "71        2\n",
      "177       2\n",
      "161       2\n",
      "148       2\n",
      "132       2\n",
      "94        2\n",
      "144       2\n",
      "197       2\n",
      "203       1\n",
      "268       1\n",
      "147       1\n",
      "210       1\n",
      "214       1\n",
      "121       1\n",
      "128       1\n",
      "129       1\n",
      "260       1\n",
      "171       1\n",
      "127       1\n",
      "189       1\n",
      "251       1\n",
      "109       1\n",
      "97        1\n",
      "181       1\n",
      "98        1\n",
      "259       1\n",
      "139       1\n",
      "568       1\n",
      "99        1\n",
      "119       1\n",
      "176       1\n",
      "243       1\n",
      "135       1\n",
      "79        1\n",
      "162       1\n",
      "111       1\n",
      "169       1\n",
      "234       1\n",
      "253       1\n",
      "96        1\n",
      "145       1\n",
      "141       1\n",
      "134       1\n",
      "232       1\n",
      "233       1\n",
      "104       1\n",
      "188       1\n",
      "103       1\n",
      "167       1\n",
      "193       1\n",
      "118       1\n",
      "106       1\n",
      "108       1\n",
      "266       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of unique values in 'num_reviews' column\n",
    "print(\"Number of unique values in 'num_reviews':\", len(df['num_reviews'].value_counts()))\n",
    "\n",
    "# Display the value counts for 'num_reviews'\n",
    "print(\"\\nValue counts for 'num_reviews':\")\n",
    "print(df['num_reviews'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8c261514-caba-4f92-8022-6001ffebec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'cuisines_offered': 388\n",
      "\n",
      "Value counts for 'cuisines_offered':\n",
      "cuisines_offered\n",
      "['Thai', 'Restaurants']                                                          640\n",
      "['American (New)', 'Restaurants']                                                596\n",
      "['American (Traditional)', 'Restaurants']                                        589\n",
      "['Mexican', 'Restaurants']                                                       572\n",
      "['Pizza', 'Restaurants']                                                         524\n",
      "['Vietnamese', 'Restaurants']                                                    465\n",
      "['Japanese', 'Sushi Bars', 'Restaurants']                                        459\n",
      "['Sandwiches', 'Restaurants']                                                    430\n",
      "['Chinese', 'Restaurants']                                                       394\n",
      "['Italian', 'Pizza', 'Restaurants']                                              327\n",
      "['Japanese', 'Restaurants']                                                      282\n",
      "['Italian', 'Restaurants']                                                       274\n",
      "['Restaurants']                                                                  237\n",
      "['Fast Food', 'Mexican', 'Restaurants']                                          232\n",
      "['Delis', 'Restaurants']                                                         204\n",
      "['Cafes', 'Sandwiches', 'Restaurants']                                           195\n",
      "['Burgers', 'Fast Food', 'Restaurants']                                          180\n",
      "['Greek', 'Mediterranean', 'Restaurants']                                        177\n",
      "['American (Traditional)', 'Breakfast & Brunch', 'Restaurants']                  168\n",
      "['Fast Food', 'Sandwiches', 'Restaurants']                                       159\n",
      "['Ethiopian', 'Restaurants']                                                     136\n",
      "['Burgers', 'Restaurants']                                                       136\n",
      "['Irish', 'Restaurants']                                                         135\n",
      "['Delis', 'Sandwiches', 'Restaurants']                                           121\n",
      "['Dim Sum', 'Seafood', 'Cantonese', 'Chinese', 'Restaurants']                    118\n",
      "['Seafood', 'Restaurants']                                                        97\n",
      "['Barbeque', 'Restaurants']                                                       91\n",
      "['Italian', 'Pizza', 'Sandwiches', 'Restaurants']                                 86\n",
      "['French', 'Restaurants']                                                         85\n",
      "['Creperies', 'Restaurants']                                                      84\n",
      "['Breakfast & Brunch', 'Restaurants']                                             84\n",
      "['Cafes', 'Restaurants']                                                          84\n",
      "['Indian', 'Restaurants']                                                         80\n",
      "['Breakfast & Brunch', 'Cafes', 'Restaurants']                                    79\n",
      "['Vietnamese', 'Sandwiches', 'Restaurants']                                       77\n",
      "['Delis', 'Vietnamese', 'Sandwiches', 'Restaurants']                              76\n",
      "['Seafood', 'Fast Food', 'Fish & Chips', 'Restaurants']                           69\n",
      "['Breakfast & Brunch', 'American (New)', 'Restaurants']                           68\n",
      "['Indian', 'Buffets', 'Restaurants']                                              67\n",
      "['Japanese', 'Chinese', 'Restaurants']                                            64\n",
      "['German', 'Restaurants']                                                         64\n",
      "['Asian Fusion', 'Chinese', 'Restaurants']                                        63\n",
      "['Barbeque', 'Chinese', 'Restaurants']                                            59\n",
      "['Asian Fusion', 'Restaurants']                                                   53\n",
      "['Breakfast & Brunch', 'Seafood', 'Buffets', 'Restaurants']                       51\n",
      "['Breakfast & Brunch', 'Sandwiches', 'Restaurants']                               51\n",
      "['Mediterranean', 'Restaurants']                                                  49\n",
      "['American (New)', 'French', 'Restaurants']                                       47\n",
      "['Restaurants', 'Pizza']                                                          45\n",
      "['Delis', 'Italian', 'Restaurants']                                               44\n",
      "['American (Traditional)', 'Seafood', 'Restaurants']                              41\n",
      "['Mexican', 'Sandwiches', 'Restaurants']                                          41\n",
      "['British', 'Restaurants']                                                        41\n",
      "['Steakhouses', 'Restaurants']                                                    40\n",
      "['American (Traditional)', 'Soup', 'Seafood', 'Restaurants']                      40\n",
      "['American (Traditional)', 'Steakhouses', 'Restaurants']                          40\n",
      "['Pakistani', 'Indian', 'Restaurants']                                            38\n",
      "['Mexican', 'Tex-Mex', 'Restaurants']                                             38\n",
      "['Cantonese', 'Chinese', 'Restaurants']                                           37\n",
      "['Vegetarian', 'Vegan', 'Restaurants']                                            37\n",
      "['Filipino', 'Restaurants']                                                       37\n",
      "['Tapas Bars', 'Spanish', 'Basque', 'Restaurants']                                36\n",
      "['Tex-Mex', 'Restaurants']                                                        35\n",
      "['Seafood', 'Steakhouses', 'Restaurants']                                         34\n",
      "['American (Traditional)', 'Burgers', 'Restaurants']                              34\n",
      "['Cheesesteaks', 'Sandwiches', 'Restaurants']                                     34\n",
      "['Vietnamese', 'Chinese', 'Restaurants']                                          33\n",
      "['Breakfast & Brunch', 'Diners', 'Restaurants']                                   31\n",
      "['Mediterranean', 'Middle Eastern', 'Restaurants']                                31\n",
      "['Dim Sum', 'Cantonese', 'Chinese', 'Restaurants']                                31\n",
      "['Sushi Bars', 'Restaurants']                                                     29\n",
      "['Fast Food', 'Southern', 'Soul Food', 'Restaurants']                             29\n",
      "['American (Traditional)', 'Diners', 'Restaurants']                               28\n",
      "['Breakfast & Brunch', 'Vegetarian', 'Restaurants']                               28\n",
      "['Seafood', 'Cantonese', 'Chinese', 'Restaurants']                                27\n",
      "['American (Traditional)', 'Breakfast & Brunch', 'Diners', 'Restaurants']         27\n",
      "['Greek', 'Mediterranean', 'Middle Eastern', 'Restaurants']                       27\n",
      "['Burgers', 'American (New)', 'Restaurants']                                      26\n",
      "['Turkish', 'Mediterranean', 'Restaurants']                                       26\n",
      "['Hawaiian', 'Restaurants']                                                       26\n",
      "['Barbeque', 'Chicken Wings', 'Restaurants']                                      26\n",
      "['American (Traditional)', 'American (New)', 'Restaurants']                       25\n",
      "['Middle Eastern', 'Restaurants']                                                 23\n",
      "['Sushi Bars', 'Japanese', 'Hawaiian', 'Restaurants']                             23\n",
      "['Seafood', 'American (New)', 'Restaurants']                                      23\n",
      "['Burgers', 'Gluten-Free', 'Restaurants']                                         23\n",
      "['Hot Pot', 'Szechuan', 'Chinese', 'Restaurants']                                 23\n",
      "['Cuban', 'Caribbean', 'Sandwiches', 'Restaurants']                               23\n",
      "['Gluten-Free', 'Restaurants']                                                    22\n",
      "['Cafes', 'French', 'Restaurants']                                                21\n",
      "['Korean', 'Japanese', 'Chinese', 'Restaurants']                                  21\n",
      "['Breakfast & Brunch', 'Burgers', 'Restaurants']                                  21\n",
      "['Dim Sum', 'Chinese', 'Restaurants']                                             21\n",
      "['Restaurants', 'Cafes']                                                          21\n",
      "['Seafood', 'Chinese', 'Restaurants']                                             21\n",
      "['Cajun/Creole', 'Restaurants']                                                   21\n",
      "['Diners', 'Restaurants']                                                         20\n",
      "['Seafood', 'Breakfast & Brunch', 'Restaurants']                                  20\n",
      "['Asian Fusion', 'Sushi Bars', 'Restaurants']                                     20\n",
      "['Korean', 'Japanese', 'Restaurants']                                             20\n",
      "['Indian', 'Himalayan/Nepalese', 'Restaurants']                                   20\n",
      "['Dim Sum', 'Cantonese', 'Barbeque', 'Chinese', 'Restaurants']                    20\n",
      "['Breakfast & Brunch', 'American (New)', 'Cafes', 'Restaurants']                  19\n",
      "['Cambodian', 'Restaurants']                                                      19\n",
      "['Breakfast & Brunch', 'French', 'Restaurants']                                   19\n",
      "['Tapas Bars', 'American (New)', 'Restaurants']                                   18\n",
      "['Greek', 'Restaurants']                                                          18\n",
      "['Fast Food', 'Japanese', 'Restaurants']                                          18\n",
      "['Pakistani', 'Indian', 'Buffets', 'Restaurants']                                 18\n",
      "['Pizza', 'Sandwiches', 'Restaurants']                                            18\n",
      "['Chinese', 'Dim Sum', 'Seafood', 'Restaurants']                                  18\n",
      "['Brazilian', 'Restaurants']                                                      18\n",
      "['Modern European', 'American (New)', 'Restaurants']                              18\n",
      "['Fast Food', 'Chinese', 'Restaurants']                                           18\n",
      "['Russian', 'Restaurants']                                                        18\n",
      "['Tapas Bars', 'Restaurants']                                                     17\n",
      "['Breakfast & Brunch', 'Creperies', 'Restaurants']                                17\n",
      "['American (New)', 'Sandwiches', 'Restaurants']                                   17\n",
      "['Vegetarian', 'Restaurants']                                                     17\n",
      "['Seafood', 'Italian', 'Restaurants']                                             17\n",
      "['Mexican', 'Salvadoran', 'Latin American', 'Restaurants']                        16\n",
      "['Barbeque', 'Soul Food', 'Restaurants']                                          16\n",
      "['American (Traditional)', 'Cafes', 'Restaurants']                                16\n",
      "['Burgers', 'Hot Dogs', 'Restaurants']                                            16\n",
      "['Asian Fusion', 'Japanese', 'Restaurants']                                       16\n",
      "['Vietnamese', 'Sandwiches', 'Japanese', 'Restaurants']                           16\n",
      "['Korean', 'Restaurants']                                                         16\n",
      "['American (Traditional)', 'Breakfast & Brunch', 'Burgers', 'Restaurants']        16\n",
      "['Restaurants', 'Mexican']                                                        16\n",
      "['Pizza', 'Gluten-Free', 'Restaurants']                                           16\n",
      "['Asian Fusion', 'Japanese', 'Sushi Bars', 'Restaurants']                         15\n",
      "['Pakistani', 'Indian', 'Halal', 'Restaurants']                                   15\n",
      "['Breakfast & Brunch', 'Vietnamese', 'Restaurants']                               15\n",
      "['Asian Fusion', 'Dim Sum', 'Vietnamese', 'Chinese', 'Restaurants']               15\n",
      "['Breakfast & Brunch', 'Mexican', 'Restaurants']                                  15\n",
      "['Restaurants', 'Italian']                                                        15\n",
      "['Moroccan', 'Restaurants']                                                       14\n",
      "['African', 'Restaurants']                                                        14\n",
      "['Vegetarian', 'Vietnamese', 'Restaurants']                                       14\n",
      "['Asian Fusion', 'Gluten-Free', 'Chinese', 'Restaurants']                         14\n",
      "['American (Traditional)', 'Breakfast & Brunch', 'Vegetarian', 'Restaurants']     14\n",
      "['Mediterranean', 'Gastropubs', 'Restaurants']                                    14\n",
      "['Breakfast & Brunch', 'Delis', 'Burgers', 'Restaurants']                         14\n",
      "['Vegetarian', 'Vegan', 'Hot Dogs', 'Restaurants']                                14\n",
      "['Thai', 'Chinese', 'Restaurants']                                                14\n",
      "['Delis', 'Vietnamese', 'Restaurants']                                            14\n",
      "['Taiwanese', 'Chinese', 'Restaurants']                                           14\n",
      "['Asian Fusion', 'Thai', 'Chinese', 'Restaurants']                                14\n",
      "['Thai', 'Vietnamese', 'Restaurants']                                             14\n",
      "['Soup', 'Restaurants']                                                           13\n",
      "['Pizza', 'Gluten-Free', 'Vegan', 'Restaurants']                                  13\n",
      "['German', 'Steakhouses', 'Restaurants']                                          13\n",
      "['Italian', 'Pizza', 'Cafes', 'Restaurants']                                      13\n",
      "['Pizza', 'American (New)', 'Restaurants']                                        13\n",
      "['Sandwiches', 'French', 'Restaurants']                                           13\n",
      "['Breakfast & Brunch', 'Seafood', 'American (New)', 'Restaurants']                13\n",
      "['American (Traditional)', 'Sandwiches', 'Restaurants']                           13\n",
      "['Gastropubs', 'Restaurants']                                                     13\n",
      "['American (Traditional)', 'Breakfast & Brunch', 'Seafood', 'Restaurants']        13\n",
      "['Shanghainese', 'Chinese', 'Restaurants']                                        13\n",
      "['Fondue', 'Gluten-Free', 'Restaurants']                                          13\n",
      "['Barbeque', 'Hawaiian', 'Restaurants']                                           13\n",
      "['Vegetarian', 'Modern European', 'Mediterranean', 'Restaurants']                 13\n",
      "['Pizza', 'Fast Food', 'Restaurants']                                             13\n",
      "['German', 'Sandwiches', 'Restaurants']                                           13\n",
      "['Tapas/Small Plates', 'Mediterranean', 'Restaurants']                            13\n",
      "['Creperies', 'Sandwiches', 'Restaurants']                                        13\n",
      "['Mexican', 'Latin American', 'Restaurants']                                      13\n",
      "['Creperies', 'Food Stands', 'Restaurants']                                       12\n",
      "['Barbeque', 'Southern', 'Restaurants']                                           12\n",
      "['Southern', 'Restaurants']                                                       12\n",
      "['Mongolian', 'Restaurants']                                                      12\n",
      "['Hot Dogs', 'Restaurants']                                                       12\n",
      "['Mediterranean', 'Italian', 'Pizza', 'Restaurants']                              12\n",
      "['Gastropubs', 'American (New)', 'Restaurants']                                   12\n",
      "['Salvadoran', 'Latin American', 'Restaurants']                                   12\n",
      "['American (New)', 'Diners', 'Restaurants']                                       12\n",
      "['Modern European', 'Sandwiches', 'Restaurants']                                  12\n",
      "['Burgers', 'Sandwiches', 'Restaurants']                                          12\n",
      "['Sushi Bars', 'Japanese', 'Chinese', 'Restaurants']                              12\n",
      "['Burgers', 'Breakfast & Brunch', 'Restaurants']                                  12\n",
      "['Szechuan', 'Chinese', 'Restaurants']                                            12\n",
      "['American (Traditional)', 'Burgers', 'Sandwiches', 'Restaurants']                12\n",
      "['Delis', 'Turkish', 'Restaurants']                                               11\n",
      "['Breakfast & Brunch', 'Delis', 'Restaurants']                                    11\n",
      "['Breakfast & Brunch', 'Cafes', 'Ethiopian', 'Restaurants']                       11\n",
      "['Modern European', 'Restaurants']                                                11\n",
      "['Indian', 'Mediterranean', 'Restaurants']                                        11\n",
      "['Seafood', 'French', 'Restaurants']                                              11\n",
      "['Mediterranean', 'Greek', 'Restaurants']                                         11\n",
      "['Afghan', 'Restaurants']                                                         11\n",
      "['Burgers', 'Pizza', 'Restaurants']                                               11\n",
      "['Vegetarian', 'Ethiopian', 'Vegan', 'Restaurants']                               11\n",
      "['Persian/Iranian', 'Restaurants']                                                11\n",
      "['American (Traditional)', 'Breakfast & Brunch', 'Cafes', 'Restaurants']          11\n",
      "['Modern European', 'Restaurants', 'Belgian']                                     11\n",
      "['Restaurants', 'American (New)']                                                 11\n",
      "['Caribbean', 'Haitian', 'Restaurants']                                           11\n",
      "['Trinidadian', 'Caribbean', 'Restaurants']                                       11\n",
      "['Chinese', 'Dim Sum', 'Restaurants']                                             11\n",
      "['Food Stands', 'Hot Dogs', 'Restaurants']                                        11\n",
      "['Korean', 'Japanese', 'Sushi Bars', 'Restaurants']                               11\n",
      "['Malaysian', 'Restaurants']                                                      11\n",
      "['Burgers', 'Seafood', 'Fish & Chips', 'Restaurants']                             11\n",
      "['Live/Raw Food', 'Vegan', 'Restaurants']                                         11\n",
      "['Seafood', 'Japanese', 'Sushi Bars', 'Restaurants']                              10\n",
      "['Vegetarian', 'Indian', 'Restaurants']                                           10\n",
      "['Restaurants', 'Sandwiches']                                                     10\n",
      "['Polish', 'Delis', 'Restaurants']                                                10\n",
      "['Cajun/Creole', 'Diners', 'Restaurants']                                         10\n",
      "['Vietnamese', 'Food Court', 'Sandwiches', 'Restaurants']                         10\n",
      "['Greek', 'Pizza', 'Mediterranean', 'Restaurants']                                10\n",
      "['Greek', 'American (New)', 'Restaurants']                                        10\n",
      "['Seafood', 'Live/Raw Food', 'Restaurants']                                       10\n",
      "['Soup', 'Delis', 'Restaurants']                                                  10\n",
      "['Fast Food', 'Buffets', 'Chinese', 'Restaurants']                                10\n",
      "['Italian', 'Basque', 'Spanish', 'Restaurants']                                   10\n",
      "['Fast Food', 'Food Stands', 'Restaurants']                                       10\n",
      "['Mediterranean', 'Moroccan', 'Restaurants']                                      10\n",
      "['Gluten-Free', 'Japanese', 'Sushi Bars', 'Restaurants']                           9\n",
      "['Thai', 'Vegetarian', 'Restaurants']                                              9\n",
      "['Vietnamese', 'Japanese', 'Restaurants']                                          9\n",
      "['Barbeque', 'Korean', 'Food Court', 'Restaurants']                                9\n",
      "['Delis', 'Mexican', 'Restaurants']                                                9\n",
      "['Vegetarian', 'Gluten-Free', 'Vegan', 'Restaurants']                              9\n",
      "['Seafood', 'Fish & Chips', 'Restaurants']                                         9\n",
      "['Seafood', 'Diners', 'Restaurants']                                               9\n",
      "['German', 'Fast Food', 'Restaurants']                                             9\n",
      "['Cantonese', 'Barbeque', 'Chinese', 'Restaurants']                                9\n",
      "['Burgers', 'Seafood', 'Restaurants']                                              9\n",
      "['Asian Fusion', 'Vegetarian', 'Delis', 'Restaurants']                             9\n",
      "['American (Traditional)', 'Chinese', 'Restaurants']                               9\n",
      "['Fast Food', 'Hot Dogs', 'Restaurants']                                           9\n",
      "['Southern', 'Soul Food', 'Restaurants']                                           8\n",
      "['Asian Fusion', 'Tapas Bars', 'Thai', 'Restaurants']                              8\n",
      "['Dim Sum', 'Taiwanese', 'Chinese', 'Restaurants']                                 8\n",
      "['Buffets', 'Salad', 'Restaurants']                                                8\n",
      "['Russian', 'Cafes', 'Restaurants']                                                8\n",
      "['Spanish', 'Restaurants']                                                         8\n",
      "['Cantonese', 'Vietnamese', 'Chinese', 'Restaurants']                              8\n",
      "['Vegetarian', 'Vietnamese', 'Delis', 'Restaurants']                               8\n",
      "['Seafood', 'Southern', 'Soul Food', 'Restaurants']                                8\n",
      "['American (New)', 'Tapas/Small Plates', 'Restaurants']                            8\n",
      "['Asian Fusion', 'Korean', 'Sandwiches', 'Restaurants']                            8\n",
      "['Delis', 'Buffets', 'Restaurants']                                                8\n",
      "['Asian Fusion', 'Buffets', 'Restaurants']                                         8\n",
      "['Fast Food', 'Restaurants']                                                       8\n",
      "['American (New)', 'Breakfast & Brunch', 'Restaurants']                            8\n",
      "['Asian Fusion', 'Indonesian', 'Restaurants']                                      7\n",
      "['Cafes', 'Gluten-Free', 'Restaurants']                                            7\n",
      "['Soup', 'Sandwiches', 'Restaurants']                                              7\n",
      "['Pizza', 'Italian', 'Fast Food', 'Restaurants']                                   7\n",
      "['Thai', 'Laotian', 'Restaurants']                                                 7\n",
      "['Chinese', 'Sushi Bars', 'Restaurants']                                           7\n",
      "['Indian', 'Tapas/Small Plates', 'American (New)', 'Restaurants']                  7\n",
      "['Thai', 'Japanese', 'Sushi Bars', 'Restaurants']                                  7\n",
      "['Indonesian', 'Taiwanese', 'Chinese', 'Restaurants']                              7\n",
      "['Vegetarian', 'Ethiopian', 'Restaurants']                                         7\n",
      "['Asian Fusion', 'Korean', 'Hawaiian', 'Restaurants']                              7\n",
      "['Barbeque', 'Vietnamese', 'Chinese', 'Restaurants']                               7\n",
      "['Vegan', 'Restaurants']                                                           7\n",
      "['Tapas/Small Plates', 'Restaurants']                                              7\n",
      "['Caribbean', 'Restaurants']                                                       7\n",
      "['Scandinavian', 'Restaurants']                                                    7\n",
      "['Turkish', 'Sandwiches', 'Middle Eastern', 'Restaurants']                         7\n",
      "['Breakfast & Brunch', 'Cafes', 'Vegan', 'Restaurants']                            7\n",
      "['Korean', 'Barbeque', 'Chicken Wings', 'Restaurants']                             7\n",
      "['Buffets', 'Restaurants']                                                         7\n",
      "['Burgers', 'Cheesesteaks', 'Barbeque', 'Restaurants']                             7\n",
      "['Greek', 'Mediterranean', 'French', 'Restaurants']                                7\n",
      "['Korean', 'Fast Food', 'Japanese', 'Restaurants']                                 6\n",
      "['Gluten-Free', 'Vegan', 'Restaurants']                                            6\n",
      "['Vegetarian', 'Thai', 'Vegan', 'Restaurants']                                     6\n",
      "['American (Traditional)', 'Soup', 'Restaurants']                                  6\n",
      "['Cafes', 'Mediterranean', 'Restaurants']                                          6\n",
      "['Pizza', 'Vegan', 'Restaurants']                                                  6\n",
      "['Asian Fusion', 'Chicken Wings', 'Chinese', 'Restaurants']                        6\n",
      "['Vietnamese', 'French', 'Restaurants']                                            6\n",
      "['Tapas Bars', 'Italian', 'Restaurants']                                           6\n",
      "['Barbeque', 'American (New)', 'Restaurants']                                      6\n",
      "['Burgers', 'Fish & Chips', 'Restaurants']                                         6\n",
      "['Breakfast & Brunch', 'Greek', 'Restaurants']                                     6\n",
      "['Halal', 'Restaurants']                                                           6\n",
      "['Fast Food', 'American (Traditional)', 'Restaurants']                             6\n",
      "['Pizza', 'Mediterranean', 'Restaurants']                                          6\n",
      "['American (Traditional)', 'Soup', 'Sandwiches', 'Restaurants']                    6\n",
      "['Asian Fusion', 'Vietnamese', 'Restaurants']                                      6\n",
      "['Breakfast & Brunch', 'Burgers', 'American (New)', 'Restaurants']                 6\n",
      "['Food Stands', 'Mexican', 'Restaurants']                                          6\n",
      "['Asian Fusion', 'American (New)', 'Restaurants']                                  5\n",
      "['Barbeque', 'Mediterranean', 'Restaurants']                                       5\n",
      "['Seafood', 'American (New)', 'Live/Raw Food', 'Restaurants']                      5\n",
      "['Vegetarian', 'Pizza', 'Vegan', 'Restaurants']                                    5\n",
      "['Tapas Bars', 'Restaurants', 'Pizza']                                             5\n",
      "['Tapas/Small Plates', 'Breakfast & Brunch', 'Restaurants']                        5\n",
      "['Italian', 'American (New)', 'Restaurants']                                       5\n",
      "['Kosher', 'Burgers', 'Halal', 'Restaurants']                                      5\n",
      "['Lebanese', 'Mediterranean', 'Middle Eastern', 'Restaurants']                     5\n",
      "['Seafood', 'Indian', 'Restaurants']                                               5\n",
      "['Mexican', 'Caribbean', 'Restaurants']                                            5\n",
      "['Chicken Wings', 'Restaurants']                                                   5\n",
      "['Breakfast & Brunch', 'Italian', 'Pizza', 'Restaurants']                          5\n",
      "['Vegan', 'Live/Raw Food', 'Restaurants']                                          5\n",
      "['Vegetarian', 'Live/Raw Food', 'Restaurants']                                     5\n",
      "['Turkish', 'Italian', 'Mediterranean', 'Restaurants']                             5\n",
      "['Fast Food', 'Chicken Wings', 'Restaurants']                                      5\n",
      "['Breakfast & Brunch', 'Sandwiches', 'Filipino', 'Restaurants']                    5\n",
      "['Vegetarian', 'Pizza', 'Restaurants']                                             4\n",
      "['Italian', 'Cafes', 'Sandwiches', 'Restaurants']                                  4\n",
      "['Breakfast & Brunch', 'Belgian', 'Restaurants']                                   4\n",
      "['Cafes', 'Delis', 'Restaurants']                                                  4\n",
      "['Asian Fusion', 'Burgers', 'Restaurants']                                         4\n",
      "['Puerto Rican', 'Caribbean', 'Restaurants']                                       4\n",
      "['Buffets', 'Chinese', 'Restaurants']                                              4\n",
      "['Breakfast & Brunch', 'American (New)', 'Diners', 'Restaurants']                  4\n",
      "['Food Stands', 'Mexican', 'Salvadoran', 'Latin American', 'Restaurants']          4\n",
      "['Delis', 'Japanese', 'Restaurants']                                               4\n",
      "['American (Traditional)', 'Mediterranean', 'Restaurants']                         4\n",
      "['German', 'Cafes', 'Sandwiches', 'Restaurants']                                   4\n",
      "['Vietnamese', 'Sandwiches', 'Chinese', 'Restaurants']                             4\n",
      "['Burgers', 'Chicken Wings', 'Restaurants']                                        4\n",
      "['Delis', 'Indian', 'Restaurants']                                                 4\n",
      "['Belgian', 'Sandwiches', 'Restaurants']                                           4\n",
      "['African', 'Ethiopian', 'Restaurants']                                            3\n",
      "['Asian Fusion', 'Thai', 'Restaurants']                                            3\n",
      "['Italian', 'Food Stands', 'Restaurants']                                          3\n",
      "['Burgers', 'Barbeque', 'Restaurants']                                             3\n",
      "['Cafes', 'Sandwiches', 'Japanese', 'Restaurants']                                 3\n",
      "['Seafood', 'Cajun/Creole', 'Diners', 'Restaurants']                               3\n",
      "['Vietnamese', 'Cafes', 'Restaurants']                                             3\n",
      "['Creperies', 'Sandwiches', 'Cafes', 'Restaurants']                                3\n",
      "['Himalayan/Nepalese', 'Restaurants']                                              3\n",
      "['Cafes', 'Latin American', 'Restaurants']                                         3\n",
      "['Seafood', 'Cajun/Creole', 'Soul Food', 'Restaurants']                            3\n",
      "['Kosher', 'Vegetarian', 'Vegan', 'Chinese', 'Restaurants']                        3\n",
      "['Caribbean', 'Latin American', 'Restaurants']                                     3\n",
      "['Delis', 'Comfort Food', 'Sandwiches', 'Restaurants']                             3\n",
      "['American (Traditional)', 'Modern European', 'Restaurants']                       3\n",
      "['Italian', 'Sandwiches', 'Restaurants']                                           3\n",
      "['Cuban', 'Venezuelan', 'Colombian', 'Latin American', 'Restaurants']              3\n",
      "['Pizza', 'Sandwiches', 'Hot Dogs', 'Restaurants']                                 2\n",
      "['German', 'Gastropubs', 'Hot Dogs', 'Restaurants']                                2\n",
      "['Asian Fusion', 'Hot Pot', 'Japanese', 'Restaurants']                             2\n",
      "['Fish & Chips', 'Restaurants']                                                    2\n",
      "['Lebanese', 'Middle Eastern', 'Restaurants']                                      2\n",
      "['Creperies', 'Sandwiches', 'French', 'Restaurants']                               2\n",
      "['Scottish', 'Restaurants']                                                        2\n",
      "['Australian', 'Restaurants']                                                      2\n",
      "['Breakfast & Brunch', 'Cafes', 'Sandwiches', 'Restaurants']                       2\n",
      "['Seafood', 'Thai', 'Restaurants']                                                 2\n",
      "['Kosher', 'Restaurants']                                                          2\n",
      "['Indonesian', 'Restaurants']                                                      2\n",
      "['Creperies', 'Food Court', 'Restaurants']                                         2\n",
      "['Barbeque', 'Sandwiches', 'Restaurants']                                          2\n",
      "['American (New)', 'Cafes', 'Restaurants']                                         2\n",
      "['Caribbean', 'Cuban', 'Restaurants']                                              2\n",
      "['Vietnamese', 'Tapas Bars', 'Restaurants']                                        2\n",
      "['Burgers', 'Japanese', 'Restaurants']                                             2\n",
      "['Cafes', 'Chinese', 'Restaurants']                                                2\n",
      "['Burgers', 'Pizza', 'American (New)', 'Restaurants']                              2\n",
      "['Senegalese', 'African', 'Restaurants']                                           2\n",
      "['Cafes', 'American (New)', 'Restaurants']                                         2\n",
      "['Steakhouses', 'American (New)', 'Restaurants']                                   1\n",
      "['Greek', 'Italian', 'Pizza', 'Restaurants']                                       1\n",
      "['Cafes', 'Southern', 'Restaurants']                                               1\n",
      "['Salad', 'Restaurants']                                                           1\n",
      "['Asian Fusion', 'Korean', 'Restaurants']                                          1\n",
      "['American (Traditional)', 'Seafood', 'Fish & Chips', 'Restaurants']               1\n",
      "['American (Traditional)', 'Vegetarian', 'Vegan', 'Restaurants']                   1\n",
      "['Italian', 'Cafes', 'Restaurants']                                                1\n",
      "['Steakhouses', 'Brazilian', 'Restaurants']                                        1\n",
      "['Sandwiches', 'Delis', 'Restaurants']                                             1\n",
      "['Mongolian', 'Japanese', 'Restaurants']                                           1\n",
      "['American (New)', 'Salvadoran', 'Latin American', 'Restaurants']                  1\n",
      "['Korean', 'Cafes', 'Restaurants']                                                 1\n",
      "['African', 'Mediterranean', 'Restaurants']                                        1\n",
      "['Mongolian', 'Chinese', 'Restaurants']                                            1\n",
      "['Persian/Iranian', 'Sandwiches', 'Middle Eastern', 'Restaurants']                 1\n",
      "['Comfort Food', 'Restaurants']                                                    1\n",
      "['Chinese', 'Dim Sum', 'Restaurants', 'Barbeque']                                  1\n",
      "['Cheesesteaks', 'Food Stands', 'Hot Dogs', 'Restaurants']                         1\n",
      "['Spanish', 'Mediterranean', 'Moroccan', 'Restaurants']                            1\n",
      "['Seafood', 'Cajun/Creole', 'Restaurants']                                         1\n",
      "['Thai', 'Pakistani', 'Restaurants']                                               1\n",
      "['Egyptian', 'Mediterranean', 'Middle Eastern', 'Restaurants']                     1\n",
      "['American (Traditional)', 'Delis', 'Restaurants']                                 1\n",
      "['Breakfast & Brunch', 'Seafood', 'Restaurants']                                   1\n",
      "['Asian Fusion', 'Korean', 'Mexican', 'Restaurants']                               1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of unique values in 'cuisines_offered' column\n",
    "print(\"Number of unique values in 'cuisines_offered':\", len(df['cuisines_offered'].value_counts()))\n",
    "\n",
    "# Display the value counts for 'cuisines_offered'\n",
    "print(\"\\nValue counts for 'cuisines_offered':\")\n",
    "print(df['cuisines_offered'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e1a9d8d4-7d13-447c-8619-23ec12587b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in 'avg_rating': 5\n",
      "Number of unique values in 'zipcode': 30\n"
     ]
    }
   ],
   "source": [
    "# Print the count of unique values in 'avg_rating' column\n",
    "print(\"Number of unique values in 'avg_rating':\", len(df['avg_rating'].value_counts()))\n",
    "\n",
    "# Print the count of unique values in 'zipcode' column\n",
    "print(\"Number of unique values in 'zipcode':\", len(df['zipcode'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c1dcf639-35ad-4582-b208-dfbb116ad20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 scores: [0.63551402 0.7027027  0.65486726 0.63636364 0.52272727]\n",
      "Average F1-Score: 0.63043\n",
      "Execution time: 17.63 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start measuring execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cuisines_offered', CountVectorizer(), 'cuisines_offered'),\n",
    "            ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "            ('num_reviews', CountVectorizer(token_pattern=r'\\d+'), 'num_reviews'),\n",
    "            ('avg_rating', CountVectorizer(token_pattern=r'\\d+'), 'avg_rating'),\n",
    "            ('text', TfidfVectorizer(\n",
    "                        stop_words='english',\n",
    "                        strip_accents='unicode',\n",
    "                        min_df=3,\n",
    "                        max_df=0.5,\n",
    "                        ngram_range=(1, 3),\n",
    "                        max_features=500), 'preprocessed_texts')],\n",
    "        remainder='passthrough'\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# Assuming train_preprocessed and train_labels are defined and contain your data\n",
    "scores = cross_val_score(pipeline, train_preprocessed, train_labels, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1 scores:\", scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))\n",
    "\n",
    "# Calculate and print the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: %0.2f seconds\" % execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f62138-419e-43e2-beac-4897f838b938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0817d6f6-8b7f-457d-8eff-be4d802df9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation F1 scores: [0.63551402 0.69090909 0.64285714 0.64220183 0.50574713]\n",
      "Average F1-Score: 0.62345\n",
      "Execution time: 21.36 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start measuring execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('union', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cuisines_offered', CountVectorizer(), 'cuisines_offered'),\n",
    "            ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "            ('num_reviews', CountVectorizer(token_pattern=r'\\d+'), 'num_reviews'),\n",
    "            ('avg_rating', CountVectorizer(token_pattern=r'\\d+'), 'avg_rating'),\n",
    "            ('text', TfidfVectorizer(\n",
    "                        stop_words='english',\n",
    "                        strip_accents='unicode',\n",
    "                        min_df=15,\n",
    "                        max_df=0.5,\n",
    "                        ngram_range=(1, 3),\n",
    "                        max_features=500), 'text')],\n",
    "        remainder='passthrough'\n",
    "    )),\n",
    "    ('clf', MultinomialNB())\n",
    "], verbose=False)\n",
    "\n",
    "# Assuming train and train_labels are defined and contain your data\n",
    "scores = cross_val_score(pipeline, train, train_labels, cv=5, scoring='f1')\n",
    "print(\"Cross-validation F1 scores:\", scores)\n",
    "print(\"Average F1-Score: %0.5f\" % np.average(scores))\n",
    "\n",
    "# Calculate and print the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time: %0.2f seconds\" % execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2b9839c6-d86e-4638-a0b3-c33103a658fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "#Create function for testing\n",
    "\n",
    "%%time\n",
    "def test_classifier(clf, X, y, vectorizer, text_col='text'):\n",
    "    pipeline = Pipeline([\n",
    "        ('union', ColumnTransformer(\n",
    "        [('cuisines_offered', CountVectorizer(min_df=10), 'cuisines_offered'),\n",
    "         ('zipcode', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['zipcode']),\n",
    "         ('num_reviews', CountVectorizer(max_df=7, token_pattern='\\d+'), 'num_reviews'),\n",
    "         ('avg_rating', OneHotEncoder(dtype='int', handle_unknown='ignore'), ['avg_rating']),\n",
    "         ('text', vectorizer, text_col)],\n",
    "        remainder='passthrough',\n",
    "    )),\n",
    "        ('clf', clf)\n",
    "    ], verbose=False)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring= 'f1_macro')\n",
    "    print(clf)\n",
    "    print(scores)\n",
    "    cv_score = np.average(scores)\n",
    "    return cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c291c7-9ba0-4135-8caa-c216ab5e5a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ed02bf32-c46e-498b-8b2b-361c71174df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Support Vector Machine': svm.SVC(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=SEED, n_estimators=500, n_jobs=-1),\n",
    "    #'Gradient Boosting': GradientBoostingClassifier()\n",
    "    'XGBoost': XGBClassifier(n_estimators=500, \n",
    "                            max_depth=5, \n",
    "                            learning_rate=0.2, \n",
    "                            objective='binary:logistic',\n",
    "                            scale_pos_weight=2,\n",
    "                            n_jobs=-1,\n",
    "                            random_state=SEED)\n",
    "}\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "                    stop_words='english',\n",
    "                    strip_accents='unicode',\n",
    "                    min_df=3,\n",
    "                    max_df=0.5,\n",
    "                    ngram_range=(1, 3),\n",
    "                    max_features=500)\n",
    "\n",
    "bow = CountVectorizer(\n",
    "    stop_words='english',  # Use 'english' for built-in English stop words\n",
    "    strip_accents='unicode',\n",
    "    min_df=15,\n",
    "    max_df=0.5,\n",
    "    ngram_range=(1, 3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93540759-da8d-4469-97a0-4834c57a3a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BOW - No Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6b24c349-ab67-49fc-bdee-49280b1ddee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "[0.60750145 0.74309764 0.67879094 0.62385321 0.60066457]\n",
      "Naive Bayes: 0.6507815623584683, Time: 12.43 seconds\n",
      "SVC()\n",
      "[0.58402955 0.58626639 0.58209082 0.61330795 0.54821774]\n",
      "Support Vector Machine: 0.5827824909909105, Time: 17.92 seconds\n",
      "LogisticRegression()\n",
      "[0.57184265 0.56749683 0.5962963  0.61438679 0.65485665]\n",
      "Logistic Regression: 0.6009758453579122, Time: 13.54 seconds\n",
      "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=26)\n",
      "[0.67860422 0.57189208 0.52813853 0.64026403 0.61464646]\n",
      "Random Forest: 0.6067090639498269, Time: 29.16 seconds\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.2, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=26, ...)\n",
      "[0.61358314 0.58590122 0.52096011 0.69714574 0.59465855]\n",
      "XGBoost: 0.6024497534901668, Time: 31.28 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "\n",
    "# Initialize and fit the CountVectorizer (bow) outside the timing block\n",
    "bow.fit(train['text'])\n",
    "\n",
    "for clf_name, clf in classifiers.items():\n",
    "    start_time = time.time()\n",
    "    cv_score = test_classifier(clf, train, train_labels, vectorizer=bow, text_col='text')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('{}: {}, Time: {:.2f} seconds'.format(clf_name, cv_score, elapsed_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "267ba117-8f80-442d-860b-e19c3ed5c073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.6466555462885738, Time: 0.81 seconds\n",
      "Random Forest: 0.6355129274395329, Time: 7.18 seconds\n",
      "Support Vector Machine: 0.6502085070892412, Time: 6.18 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "# Sample classifiers\n",
    "classifier1 = LogisticRegression()\n",
    "classifier2 = RandomForestClassifier()\n",
    "classifier3 = SVC()\n",
    "\n",
    "# Fit the TF-IDF vectorizer on the training data\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(train_preprocessed['preprocessed_texts'])\n",
    "\n",
    "# Define your classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': classifier1,\n",
    "    'Random Forest': classifier2,\n",
    "    'Support Vector Machine': classifier3,\n",
    "    # Add your other classifiers here\n",
    "}\n",
    "\n",
    "# Function to test classifiers\n",
    "def test_classifier(clf, X, y, vectorizer, text_col):\n",
    "    X_vec = vectorizer.transform(X[text_col])\n",
    "    scores = cross_val_score(clf, X_vec, y, cv=5)\n",
    "    return scores.mean()\n",
    "\n",
    "# Iterate over classifiers and measure execution time\n",
    "for clf_name, clf in classifiers.items():\n",
    "    start_time = time.time()\n",
    "    cv_score = test_classifier(clf, train_preprocessed, train_labels, vectorizer=tfidf, text_col='preprocessed_texts')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print('{}: {}, Time: {:.2f} seconds'.format(clf_name, cv_score, elapsed_time))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4d6fea3f-9024-4136-9574-7b9f4cb34081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.5642035029190993\n",
      "Random Forest: 0.6099249374478732\n",
      "Support Vector Machine: 0.5421017514595496\n",
      "CPU times: total: 4.48 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for clf_name, clf in classifiers.items():\n",
    "    cv_score = test_classifier(clf, train, train_labels, \n",
    "                               vectorizer=tfidf, text_col='text')\n",
    "    print('{}: {}'.format(clf_name, cv_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c006d-51cc-464d-be1f-3d58e27fdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF - No Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "50fee439-2c53-46ad-9df5-cda4d06382cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.6466555462885738\n",
      "Random Forest: 0.6207673060884071\n",
      "Support Vector Machine: 0.6502085070892412\n",
      "CPU times: total: 7.45 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for clf_name, clf in classifiers.items():\n",
    "    cv_score = test_classifier(clf, train_preprocessed, train_labels, \n",
    "                               vectorizer=tfidf, text_col='preprocessed_texts')\n",
    "    print('{}: {}'.format(clf_name, cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc07a7f-a644-40c0-8156-70bd1776e517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca2436-e4ae-4d17-8bd1-47d213e02614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490ba43-fa5b-429e-b4f0-ad23a1e280fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025f2d3-7ec6-4662-8f15-6e5e883a8a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2297295-c3ac-4a91-8729-3e6e52baadcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e409df2a-2105-466e-8ab7-14f720098640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7bbcc-d3e9-43d6-a5ac-0b8b30c2415b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e819963-9240-4f8e-ba99-b89727315613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96b53c-ec5d-40d7-8cf2-33265ff7ac04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6c285-4c92-4587-b86d-1b56a961a330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fd1e7-04ee-4eed-b430-639c768754e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddeeff-bbe2-4a28-8a43-a570bf0cca22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea27c86-3c6d-4732-9096-3f200a45cd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12f4a5-aaaf-4946-ba84-3d923b288a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd34356-ec2c-4437-9470-91cd1ec38a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f72df-91bc-4deb-b9e7-cd1ea5a8a949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae324dd9-6345-48c7-bf1e-b8a6180dbbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132f21a-1146-4697-91eb-38dbb68acfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0780700-39a3-4491-b30b-e7c87cbed8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
